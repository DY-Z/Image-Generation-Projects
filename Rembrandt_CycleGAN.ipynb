{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NzI_B3oTVB1",
        "outputId": "7ffff0e0-6684-4119-bdeb-b02bc66d2f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57plyRl5mfNu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms.functional as F\n",
        "import gc\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngpu = 1\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ],
      "metadata": {
        "id": "XB3cnu9vRR3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "paint_drl = \"/content/drive/MyDrive/Research/Rembrandt/resized_paintings/\"\n",
        "photo_drl = \"/content/drive/MyDrive/Research/Rembrandt/resized_photos/\"\n"
      ],
      "metadata": {
        "id": "3tsyLjZNmsxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
        "        self.dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.img_labels = []\n",
        "\n",
        "        for image in os.listdir(self.dir):\n",
        "          self.img_labels.append(image)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.img_labels)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.dir, self.img_labels[idx])\n",
        "        image = read_image(img_path).float().to(device)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        #label = 1\n",
        "\n",
        "        return image"
      ],
      "metadata": {
        "id": "dZhxoWvbGoAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize(img_tensor):\n",
        "  dim1 = (img_tensor.size()[1])//4*4\n",
        "  dim2 = (img_tensor.size()[2])//4*4\n",
        "\n",
        "  return F.resize(img_tensor, [dim1, dim2])"
      ],
      "metadata": {
        "id": "D7DcVvkErloN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paint = ImageDataset(\"/content/drive/MyDrive/Research/Rembrandt/resized_paintings/\", resize)\n",
        "photo = ImageDataset(\"/content/drive/MyDrive/Research/Rembrandt/resized_photos/\", resize)"
      ],
      "metadata": {
        "id": "IVtzw3bkKcbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collect(batch):\n",
        "  return [item for item in batch]"
      ],
      "metadata": {
        "id": "LGME0tuWayyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "paintLoader = torch.utils.data.DataLoader(paint, batch_size= 1, shuffle=True)\n",
        "photoLoader = torch.utils.data.DataLoader(photo, batch_size= 1, shuffle=True)"
      ],
      "metadata": {
        "id": "MFrPYiEgLDAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQEOuvTNktJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Network structures\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "  def __init__(self, in_channel, hidden, out_channel, filter_size, stride = 1, padding = 1, ngpu = 1):\n",
        "    super().__init__()\n",
        "    self.ngpu = ngpu\n",
        "\n",
        "    self.in_channel = in_channel\n",
        "    self.hidden = hidden\n",
        "    self.out_channel = out_channel\n",
        "\n",
        "    self.filter_size = filter_size\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(self.in_channel, self.hidden, self.filter_size, padding = self.padding),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(self.hidden, self.out_channel, self.filter_size, padding = self.padding),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    #for i,x in enumerate(batch):\n",
        "    #results = None\n",
        "    result = self.conv(x)+x\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, ngpu = 1):\n",
        "    super().__init__()\n",
        "    self.ngpu = ngpu\n",
        "    self.main = nn.Sequential(\n",
        "        nn.ReflectionPad2d(3),\n",
        "        nn.Conv2d(3, 64, 7, 1),\n",
        "        nn.InstanceNorm2d(64),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.Conv2d(64, 128, 3, 2, 1),\n",
        "        nn.Conv2d(128, 256, 3, 2, 1),\n",
        "\n",
        "        ResBlock(256, 256, 256, 3),\n",
        "        ResBlock(256, 256, 256, 3),\n",
        "        ResBlock(256, 256, 256, 3),\n",
        "        ResBlock(256, 256, 256, 3),\n",
        "        ResBlock(256, 256, 256, 3),\n",
        "        ResBlock(256, 256, 256, 3),\n",
        "        ResBlock(256, 256, 256, 3),\n",
        "        ResBlock(256, 256, 256, 3),\n",
        "        ResBlock(256, 256, 256, 3),\n",
        "\n",
        "        nn.ConvTranspose2d(256, 128, 3, 2, 1, 1),\n",
        "        nn.InstanceNorm2d(128),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(128, 64, 3, 2, 1, 1),\n",
        "        nn.InstanceNorm2d(64),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ReflectionPad2d(3),\n",
        "\n",
        "        nn.Conv2d(64, 3, 7, 1),\n",
        "        nn.InstanceNorm2d(3),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.main(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, ngpu = 1):\n",
        "    super().__init__()\n",
        "    self.ngpu = ngpu\n",
        "\n",
        "    self.main = nn.Sequential(\n",
        "\n",
        "        nn.Conv2d(3, 64, 4, 2),\n",
        "        # nn.InstanceNorm2d(),\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "\n",
        "        nn.Conv2d(64, 128, 4, 2),\n",
        "        nn.InstanceNorm2d(128),\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "\n",
        "        nn.Conv2d(128, 256, 4, 2),\n",
        "        nn.InstanceNorm2d(256),\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "\n",
        "        nn.Conv2d(256, 512, 4, 1),\n",
        "        nn.InstanceNorm2d(512),\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "\n",
        "        nn.Conv2d(512, 1, 4, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.main(x)\n"
      ],
      "metadata": {
        "id": "KzSQY4_-msvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialisation\n",
        "G_photoToPaint = Generator(ngpu).to(device)\n",
        "G_paintToPhoto = Generator(ngpu).to(device)\n",
        "\n",
        "D_paintToPhoto = Discriminator(ngpu).to(device)\n",
        "D_photoToPaint = Discriminator(ngpu).to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "LNVyyBRnmssx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)"
      ],
      "metadata": {
        "id": "5vn8qK0ldf4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_photoToPaint.apply(weights_init)\n",
        "G_paintToPhoto.apply(weights_init)\n",
        "\n",
        "D_photoToPaint.apply(weights_init)\n",
        "D_paintToPhoto.apply(weights_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVf3knhUdgsi",
        "outputId": "61652e31-4a1d-4125-e3a1-2ad705e3474b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (main): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
              "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
              "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1))\n",
              "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "NUM_EPOCH = 200\n",
        "lr_G = 2e-4\n",
        "mu = 10.0\n",
        "\n",
        "# Initialise optimisers\n",
        "from itertools import chain\n",
        "optimiser_G = torch.optim.Adam(chain(G_photoToPaint.parameters(), G_paintToPhoto.parameters()), lr = lr_G)\n",
        "optimiser_D = torch.optim.Adam(chain(D_paintToPhoto.parameters(), D_photoToPaint.parameters()), lr = lr_G)\n",
        "\n",
        "lambda_G = lambda epoch: lr_G if epoch <= 100 else (lr_G)-(2*lr_G/(epoch))*(epoch-epoch/2)\n",
        "lambda_D = lambda epoch: lr_G if epoch <= 100 else (lr_G)-(2*lr_G/(epoch))*(epoch-epoch/2)\n",
        "\n",
        "scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimiser_G, lambda_G)\n",
        "scheduler_D = torch.optim.lr_scheduler.LambdaLR(optimiser_D, lambda_D)\n"
      ],
      "metadata": {
        "id": "KaALZFSAmsqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss for lists of images\n",
        "def criterion_binary(prediction, label):\n",
        "  '''\n",
        "  prediction: 2D tensors\n",
        "  label: int. 1.0 for real, 0.0 for fake.\n",
        "  '''\n",
        "\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "  truth = torch.tensor(label).expand_as(prediction)\n",
        "  truth = truth.to(device)\n",
        "  loss  = criterion(prediction, truth)\n",
        "\n",
        "  return loss\n",
        "\n",
        "def criterion_L1(prediction, truth):\n",
        "  '''\n",
        "  prediction: list of fake images\n",
        "  truth: list of real images\n",
        "  '''\n",
        "  criterion = nn.L1Loss()\n",
        "\n",
        "  loss = criterion(prediction, truth)\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "tfsmfzB_cnQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setGrad(net, grad):\n",
        "  for param in net.parameters():\n",
        "    param.requires_grad = grad\n"
      ],
      "metadata": {
        "id": "Xsh4nfeZRW3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0 # Num of visited images\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "for epoch in range(1, NUM_EPOCH+1):\n",
        "  #Load images\n",
        "  for (paint_real, photo_real) in zip(paintLoader, photoLoader):\n",
        "    '''\n",
        "    if count%BATCH_SIZE == 0 and count > 0:\n",
        "\n",
        "    #paint_real = paint_batch\n",
        "    #photo_real = photo_batch\n",
        "\n",
        "      optimiser_G.zero_grad()\n",
        "      optimiser_D.zero_grad()\n",
        "\n",
        "      loss_G = 1.0*loss_G/BATCH_SIZE\n",
        "      loss_D = 0.5*loss_D/BATCH_SIZE\n",
        "\n",
        "      loss_G.backward()\n",
        "      loss_D.backward()\n",
        "\n",
        "      optimiser_G.step()\n",
        "      optimiser_D.step()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        torch.cuda.empty_cache()\n",
        "    '''\n",
        "    optimiser_G.zero_grad()\n",
        "    optimiser_D.zero_grad()\n",
        "\n",
        "    # Generating fake images\n",
        "    fake_paint = G_photoToPaint(photo_real)\n",
        "    fake_photo = G_paintToPhoto(paint_real)\n",
        "\n",
        "    # Fix D\n",
        "    #setGrad(D_photoToPaint, False)\n",
        "    #setGrad(D_paintToPhoto, False)\n",
        "    for param in D_paintToPhoto.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    for param in D_photoToPaint.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    # D's decisions\n",
        "    decision_fakePaint = D_photoToPaint(fake_paint.detach()) # evaluate G_photoToPaint\n",
        "    decision_fakePhoto = D_paintToPhoto(fake_photo.detach()) # evaluate G_paintToPhoto\n",
        "\n",
        "    # Cycle\n",
        "    fake_paintToPhoto = G_paintToPhoto(fake_paint) # type: photo\n",
        "    fake_photoToPaint = G_photoToPaint(fake_photo) # type: paint\n",
        "\n",
        "\n",
        "    # Calculate the loss for G\n",
        "    loss_G = criterion_binary(decision_fakePaint, 1.0) + criterion_binary(decision_fakePhoto, 1.0) + mu*(criterion_L1(fake_paintToPhoto, photo_real)+criterion_L1(fake_photoToPaint, paint_real))\n",
        "    loss_G.backward()\n",
        "    optimiser_G.step()\n",
        "\n",
        "    # Feed real images into D\n",
        "    for param in D_paintToPhoto.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    for param in D_photoToPaint.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    decision_realPaint = D_photoToPaint(paint_real)\n",
        "    decision_realPhoto = D_paintToPhoto(photo_real)\n",
        "\n",
        "    #decision_fakePaint1 = D_photoToPaint(fake_paint) # evaluate G_photoToPaint\n",
        "    #decision_fakePhoto1 = D_paintToPhoto(fake_photo) # evaluate G_paintToPhoto\n",
        "    # Loss for D\n",
        "    loss_D_A = criterion_binary(decision_realPaint, 1.0)  + criterion_binary(decision_fakePaint, 0.0)\n",
        "    loss_D_A = 0.5*loss_D_A\n",
        "    loss_D_A.backward(retain_graph=True)\n",
        "\n",
        "    loss_D_B = criterion_binary(decision_realPhoto, 1.0) + criterion_binary(decision_fakePhoto, 0.0)\n",
        "    loss_D_B = 0.5*loss_D_B\n",
        "    loss_D_B.backward(retain_graph=True)\n",
        "\n",
        "    optimiser_D.step()\n",
        "    #count += 1\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    #print(count)\n",
        "\n",
        "  scheduler_G.step()\n",
        "  scheduler_D.step()\n",
        "\n",
        "  print(\"epoch\", epoch, \"done\")\n"
      ],
      "metadata": {
        "id": "6cV_y9VsTf2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation"
      ],
      "metadata": {
        "id": "RtGvBhpymsoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "photo_batch = next(iter(photoLoader))\n",
        "fake = G_photoToPaint(photo_batch)\n",
        "#plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(fake[0],(1,2,0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G8-iibd-mslr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''from torch._C import dtype\n",
        "#from torch._C import float32\n",
        "for (paint_batch, photo_batch) in zip(paintLoader, photoLoader):\n",
        "  #F.to_tensor(paint_batch[0])\n",
        "  paint_batch[0].to(device)\n",
        "  print(paint_batch)\n",
        "  G_photoToPaint(paint_batch)\n",
        "  print(\"fine\")\n",
        "  #print(paint_batch)\n",
        "  #print(photo_batch)\n",
        "  break'''"
      ],
      "metadata": {
        "id": "DGEbi_mlmsjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Po1q6SzLmsgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7L9T9z0cmseZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uUomtsHpmscA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UvY7T6wlmsZq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}